# Small default model profile (good for low-VRAM tests)
MODEL_NAME=Qwen/Qwen2.5-0.5B-Instruct
PARALLEL_REQUESTS=2
GPU_COUNT=1

# Optional runtime tuning
OPENAI_API_KEY=EMPTY
HF_TOKEN=
VLLM_PORT=8000
GPU_MEMORY_UTILIZATION=0.9
MAX_MODEL_LEN=2048
# Optional: leave empty for full precision (for example: awq for AWQ models)
VLLM_QUANTIZATION=
# Optional vLLM scheduler/memory tuning (leave empty to keep vLLM defaults)
# VLLM_MAX_NUM_SEQS=1
# VLLM_MAX_NUM_BATCHED_TOKENS=2048
# VLLM_ENFORCE_EAGER=0
