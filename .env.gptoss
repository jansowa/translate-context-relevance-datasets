# High-throughput profile for large multi-GPU hosts
MODEL_NAME=openai/gpt-oss-120b
PARALLEL_REQUESTS=16
GPU_COUNT=4

# Optional runtime tuning
OPENAI_API_KEY=EMPTY
HF_TOKEN=
VLLM_PORT=8000
GPU_MEMORY_UTILIZATION=0.9
MAX_MODEL_LEN=4096
# Optional: leave empty for full precision (for example: awq for AWQ models)
VLLM_QUANTIZATION=
